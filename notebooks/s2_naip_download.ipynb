{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2929ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pcxarray as pcx\n",
    "import rioxarray as rxr\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from warnings import filterwarnings\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from shapely import STRtree\n",
    "from shapely import Point, Geometry\n",
    "from rtree import index\n",
    "import numpy as np\n",
    "import odc.geo.xr\n",
    "from rasterio.enums import Resampling\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "import os\n",
    "from threading import Lock\n",
    "import pandas as pd\n",
    "from planetary_computer import sign_url\n",
    "import rasterio as rio\n",
    "import math\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "max_num_samples = 500000\n",
    "min_sample_dist = 2000 # minimum distance between samples\n",
    "out_dir = os.path.join('..', 's2_naip_pairs')\n",
    "target_resolution = 1.0\n",
    "tile_size = 256\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd0fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conus_gdf = pcx.utils.load_census_shapefile(level='state')\n",
    "conus_gdf = conus_gdf.loc[~conus_gdf['STUSPS'].isin(['AK', 'HI', 'PR', 'GU', 'VI', 'MP', 'AS'])]\n",
    "# south_states = [\"AL\",\"AR\",\"DE\",\"DC\",\"FL\",\"GA\",\"KY\",\"LA\",\"MD\",\"MS\",\"NC\",\"OK\",\"SC\",\"TN\",\"TX\",\"VA\",\"WV\"]\n",
    "# conus_gdf = conus_gdf.loc[conus_gdf['STUSPS'].isin(south_states)]\n",
    "conus_geom = conus_gdf.dissolve().buffer(0.1).simplify(0.1).geometry.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e51b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "naip_observations_gdf = pd.concat([\n",
    "    pcx.pc_query(\n",
    "        collections='naip',\n",
    "        geometry=conus_geom,\n",
    "        crs=conus_gdf.crs,\n",
    "        datetime='2021',\n",
    "    ),\n",
    "    pcx.pc_query(\n",
    "        collections='naip',\n",
    "        geometry=conus_geom,\n",
    "        crs=conus_gdf.crs,\n",
    "        datetime='2022',\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a79c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1000/61975 [00:50<50:55, 19.95it/s] \n"
     ]
    }
   ],
   "source": [
    "def _query_row(geom, date_str, crs):\n",
    "    try:\n",
    "        res = pcx.pc_query(\n",
    "            collections=\"sentinel-2-l2a\",\n",
    "            geometry=geom,\n",
    "            crs=crs,\n",
    "            datetime=date_str,\n",
    "        )\n",
    "        if res is None or len(res) == 0:\n",
    "            return []\n",
    "        else:\n",
    "            return [geom.intersection(g) for g in res.geometry]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "inputs = []\n",
    "for _, row in naip_observations_gdf.iterrows():\n",
    "    dt = row['properties.datetime']\n",
    "    if dt is None:\n",
    "        continue\n",
    "    inputs.append((row.geometry, dt.date().isoformat(), naip_observations_gdf.crs))\n",
    "\n",
    "n_jobs = min(16, (len(inputs) or 1))  # tune for your machine / network\n",
    "matching_regions = []\n",
    "with tqdm(total=len(inputs)) as pbar:\n",
    "    def _wrap(args):\n",
    "        res = _query_row(*args)\n",
    "        pbar.update()\n",
    "        return res\n",
    "    results = Parallel(n_jobs=n_jobs, prefer=\"threads\", batch_size=1)(\n",
    "        delayed(_wrap)(arg) for arg in inputs[:1000]\n",
    "    )\n",
    "\n",
    "for r in results:\n",
    "    matching_regions.extend(r)\n",
    "candidate_regions_gdf = gpd.GeoDataFrame({'geometry': matching_regions}, crs=naip_observations_gdf.crs)\n",
    "\n",
    "candidate_regions_gdf = gpd.GeoDataFrame({'geometry': matching_regions}, crs=naip_observations_gdf.crs)\n",
    "candidate_regions_gdf = candidate_regions_gdf.dissolve().explode().reset_index()\n",
    "candidate_regions_gdf = candidate_regions_gdf.to_crs(5070)\n",
    "candidate_regions_gdf.to_parquet(os.path.join(out_dir, 'candidate_regions.par'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50942152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling points: 100%|██████████| 1000/1000 [00:01<00:00, 764.60it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_regions_strtree = STRtree(candidate_regions_gdf.geometry)\n",
    "invalid_regions_rtree = index.Index() \n",
    "pixel_buffer = int(math.ceil((tile_size * target_resolution) / 2.0))\n",
    "\n",
    "minx, miny, maxx, maxy = candidate_regions_gdf.total_bounds\n",
    "\n",
    "n_points = max_num_samples\n",
    "sampled_points = []\n",
    "np.random.seed(1701)\n",
    "\n",
    "with tqdm(desc='Sampling points', total=n_points) as pbar:\n",
    "    while len(sampled_points) < n_points:\n",
    "        \n",
    "        sample_x = np.random.uniform(minx, maxx)\n",
    "        sample_y = np.random.uniform(miny, maxy)\n",
    "        sample_point = Point(sample_x, sample_y)\n",
    "        \n",
    "        is_valid_region = False\n",
    "        for potential_intersection in valid_regions_strtree.query(sample_point):\n",
    "            if candidate_regions_gdf.iloc[potential_intersection].geometry.contains(sample_point.buffer(pixel_buffer)):\n",
    "                is_valid_region = True\n",
    "                break\n",
    "        \n",
    "        if not is_valid_region:\n",
    "            continue\n",
    "        \n",
    "        for potential_intersection in invalid_regions_rtree.intersection(sample_point.bounds):\n",
    "            if sampled_points[potential_intersection].buffer(min_sample_dist).intersects(sample_point):\n",
    "                is_valid_region = False\n",
    "                break\n",
    "            \n",
    "        if not is_valid_region:\n",
    "            continue\n",
    "        \n",
    "        invalid_regions_rtree.insert(len(sampled_points), sample_point.buffer(min_sample_dist).bounds)\n",
    "        sampled_points.append(sample_point)\n",
    "        pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e575ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_points_gdf = gpd.GeoDataFrame(geometry=sampled_points, crs=candidate_regions_gdf.crs)\n",
    "n_digits = len(str(len(sampled_points_gdf) - 1))\n",
    "sampled_points_gdf['id'] = sampled_points_gdf.index.map(lambda x: str(x).zfill(n_digits))\n",
    "sampled_points_gdf.to_parquet(os.path.join(out_dir, 'sampled_points.par'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d67ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sampled_points_gdf)):\n",
    "    try:\n",
    "        lcmap_item_gdf = pcx.pc_query(\n",
    "            collections='io-lulc-annual-v02',\n",
    "            geometry=sampled_points_gdf.iloc[i].geometry,\n",
    "            crs=sampled_points_gdf.crs,\n",
    "            datetime='2021-06-01',\n",
    "        )\n",
    "\n",
    "        url = lcmap_item_gdf.iloc[0]['assets.data.href']\n",
    "        with rio.open(sign_url(url)) as src:\n",
    "            cmap = src.colormap(1)\n",
    "        \n",
    "        break\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1094c0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples:   5%|▍         | 49/1000 [01:57<50:34,  3.19s/sample]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 190\u001b[39m\n\u001b[32m    187\u001b[39m             pbar.update(\u001b[32m1\u001b[39m)\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# run in threads so shared tqdm updates work\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_wrap_process_sample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampled_points_gdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m..\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms2_naip_pairs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# results = [process_sample(row, sampled_points_gdf.crs, out_dir) for row in rows[:100]]\u001b[39;00m\n\u001b[32m    197\u001b[39m pbar.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/diffusion-examples/.venv/lib/python3.13/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/diffusion-examples/.venv/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/diffusion-examples/.venv/lib/python3.13/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples:   5%|▌         | 54/1000 [02:11<39:54,  2.53s/sample]  "
     ]
    }
   ],
   "source": [
    "valid_scl_values = [4, 5, 6, 0] \n",
    "\n",
    "os.makedirs(os.path.join(out_dir, 'sentinel2'), exist_ok=True)\n",
    "os.makedirs(os.path.join(out_dir, 'naip'), exist_ok=True)\n",
    "os.makedirs(os.path.join(out_dir, 'lcmap'), exist_ok=True)\n",
    "\n",
    "def process_sample(\n",
    "    sample_row,\n",
    "    crs,\n",
    "    out_dir,\n",
    "    valid_scl_values=(0, 4, 5, 6), # nodata (will check again), vegetation, not-vegetated, water\n",
    "    target_resolution=target_resolution,\n",
    "    resampling_method=Resampling.lanczos,\n",
    "    tile_size=tile_size,\n",
    "    write_opts=None\n",
    ") -> None:\n",
    "    \n",
    "    try:\n",
    "        sid = sample_row.id\n",
    "        pixel_buffer = int(math.ceil((tile_size * target_resolution) / 2.0))\n",
    "        geom = sample_row.geometry.buffer(pixel_buffer).envelope\n",
    "\n",
    "        naip_items_gdf = pcx.pc_query(\n",
    "            collections='naip',\n",
    "            geometry=geom,\n",
    "            crs=crs,\n",
    "            datetime='2021'\n",
    "        )\n",
    "        if naip_items_gdf is None or len(naip_items_gdf) == 0:\n",
    "            return \n",
    "\n",
    "        if len(naip_items_gdf) > 1:\n",
    "            if not all(naip_items_gdf['properties.datetime'] == naip_items_gdf['properties.datetime'].iloc[0]):\n",
    "                return \n",
    "\n",
    "        naip_dt = naip_items_gdf['properties.datetime'].iloc[0].date().isoformat()\n",
    "\n",
    "        s2_items_gdf = pcx.pc_query(\n",
    "            collections='sentinel-2-l2a',\n",
    "            geometry=geom,\n",
    "            crs=crs,\n",
    "            datetime=naip_dt\n",
    "        )\n",
    "        if s2_items_gdf is None or len(s2_items_gdf) == 0:\n",
    "            return\n",
    "\n",
    "        s2_scl = pcx.prepare_data(\n",
    "            s2_items_gdf, \n",
    "            geometry=geom, \n",
    "            crs=crs, \n",
    "            bands=['SCL']\n",
    "        )\n",
    "        if not s2_scl.fillna(0).isin(valid_scl_values).all():\n",
    "            return\n",
    "\n",
    "        naip_xr = pcx.prepare_data(\n",
    "            naip_items_gdf,\n",
    "            geometry=geom,\n",
    "            crs=crs,\n",
    "            target_resolution=target_resolution,\n",
    "            resampling_method='bilinear',\n",
    "            all_touched=True\n",
    "        )\n",
    "        if naip_xr.isnull().any():\n",
    "            return \n",
    "\n",
    "        s2_xr = pcx.prepare_data(\n",
    "            s2_items_gdf,\n",
    "            geometry=geom,\n",
    "            crs=crs,\n",
    "            bands=['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12'],\n",
    "            all_touched=True,\n",
    "        )\n",
    "        if s2_xr.isnull().any():\n",
    "            return \n",
    "\n",
    "        naip_downsampled_xr = naip_xr.rio.reproject_match(s2_xr, resampling=resampling_method)\n",
    "\n",
    "        X = naip_downsampled_xr.values.reshape(naip_downsampled_xr.shape[0], -1).T\n",
    "        Y = s2_xr.sel(band=['B04', 'B03', 'B02', 'B08']).values\n",
    "        Y = Y.reshape(Y.shape[0], -1).T\n",
    "\n",
    "        valid_idx = np.where(~np.isnan(X).any(axis=1))[0]\n",
    "        if valid_idx.size == 0:\n",
    "            return \n",
    "        X = X[valid_idx]\n",
    "        Y = Y[valid_idx]\n",
    "\n",
    "        ridge = Ridge(solver='cholesky')\n",
    "        ridge.fit(X, Y)\n",
    "\n",
    "        X_full = naip_xr.values.reshape(naip_xr.shape[0], -1).T\n",
    "        naip_harmonized = ridge.predict(X_full)\n",
    "        naip_harmonized = naip_harmonized.T.reshape(naip_xr.shape)\n",
    "\n",
    "        naip_harmonized_xr = naip_xr.copy()\n",
    "        naip_harmonized_xr.values = naip_harmonized\n",
    "        naip_harmonized_xr = naip_harmonized_xr.assign_coords(band=[\"B04\", \"B03\", \"B02\", \"B08\"])\n",
    "\n",
    "        try:\n",
    "            naip_harmonized_xr = naip_harmonized_xr.isel(x=slice(0, tile_size), y=slice(0, tile_size))\n",
    "            s2_match = s2_xr.rio.reproject_match(naip_harmonized_xr, resampling=resampling_method)\n",
    "            s2_match = s2_match.isel(x=slice(0, tile_size), y=slice(0, tile_size))\n",
    "        except Exception as e:\n",
    "            return \n",
    "\n",
    "        if naip_harmonized_xr.shape[1:] != (tile_size, tile_size) or s2_match.shape[1:] != (tile_size, tile_size):\n",
    "            return \n",
    "        \n",
    "        lcmap_items_gdf = pcx.pc_query(\n",
    "            collections='io-lulc-annual-v02',\n",
    "            geometry=geom,\n",
    "            crs=crs,\n",
    "            datetime=naip_dt,\n",
    "        )\n",
    "        \n",
    "        lcmap_xr = pcx.prepare_data(\n",
    "            lcmap_items_gdf,\n",
    "            geometry=geom,\n",
    "            crs=crs,\n",
    "            all_touched=True,\n",
    "        )\n",
    "        if lcmap_xr.isnull().any():\n",
    "            return\n",
    "        lcmap_xr = lcmap_xr.rio.reproject_match(naip_xr, resampling=Resampling.nearest)\n",
    "        lcmap_xr = lcmap_xr.isel(x=slice(0, tile_size), y=slice(0, tile_size))\n",
    "\n",
    "        # clip and cast\n",
    "        naip_out = naip_harmonized_xr.clip(0, 10000).astype(np.uint16)\n",
    "        s2_out = s2_match.clip(0, 10000).astype(np.uint16)\n",
    "        lcmap_out = lcmap_xr.clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        # default write options\n",
    "        if write_opts is None:\n",
    "            write_opts = dict(\n",
    "                driver='GTiff',\n",
    "                tiled=True,\n",
    "                blockxsize=tile_size,\n",
    "                blockysize=tile_size,\n",
    "                compress='lzw',\n",
    "                interleave='pixel',\n",
    "            )\n",
    "\n",
    "        naip_path = os.path.join(out_dir, 'naip', f\"{sid}.tif\")\n",
    "        s2_path = os.path.join(out_dir, 'sentinel2', f\"{sid}.tif\")\n",
    "        lcmap_path = os.path.join(out_dir, 'lcmap', f\"{sid}.tif\")\n",
    "\n",
    "        naip_out.rio.to_raster(naip_path, **write_opts)\n",
    "\n",
    "        s2_out = s2_out.rio.write_nodata(None)\n",
    "        s2_out.rio.to_raster(s2_path, **write_opts)\n",
    "        \n",
    "        lcmap_out.rio.to_raster(lcmap_path, **write_opts)\n",
    "        with rio.open(lcmap_path, 'r+') as src:\n",
    "            src.write_colormap(1, cmap)\n",
    "        \n",
    "        return \n",
    "    \n",
    "    except Exception as e:\n",
    "        return \n",
    "\n",
    "rows = list(sampled_points_gdf.itertuples())\n",
    "n_jobs = min(16, max(1, os.cpu_count() // 2))  # tune\n",
    "\n",
    "pbar = tqdm(total=len(rows), desc=\"Processing samples\", unit=\"sample\")\n",
    "pbar_lock = Lock()\n",
    "\n",
    "def _wrap_process_sample(row, crs, out_dir, *args, **kwargs):\n",
    "    try:\n",
    "        return process_sample(row, crs, out_dir, *args, **kwargs)\n",
    "    finally:\n",
    "        with pbar_lock:\n",
    "            pbar.update(1)\n",
    "\n",
    "# run in threads so shared tqdm updates work\n",
    "results = Parallel(n_jobs=n_jobs, prefer=\"threads\", batch_size=1)(\n",
    "    delayed(_wrap_process_sample)(row, sampled_points_gdf.crs, os.path.join('..', 's2_naip_pairs'))\n",
    "    for row in rows\n",
    ")\n",
    "\n",
    "# results = [process_sample(row, sampled_points_gdf.crs, out_dir) for row in rows[:100]]\n",
    "\n",
    "pbar.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
