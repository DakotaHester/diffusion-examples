{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056a146a",
   "metadata": {},
   "source": [
    "code adapted from https://nn.labml.ai/diffusion/ddpm/unet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96495476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from diffusion_examples.modules import Swish\n",
    "\n",
    "from typing import Optional, Union, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f724f458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64\n",
      "64 128\n",
      "128 256\n",
      "256 1024\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x2048 and 4096x16384)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 245\u001b[39m\n\u001b[32m    242\u001b[39m X = torch.rand((\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m256\u001b[39m, \u001b[32m256\u001b[39m))\n\u001b[32m    243\u001b[39m t = torch.randint(\u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m, (\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/diffusion-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/diffusion-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 220\u001b[39m, in \u001b[36mUNet.forward\u001b[39m\u001b[34m(self, x, t)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     t = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtime_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     h_list = [x]\n\u001b[32m    223\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.proj(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/diffusion-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/diffusion-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mTimeEmbedding.forward\u001b[39m\u001b[34m(self, t)\u001b[39m\n\u001b[32m     26\u001b[39m embedding = t[:, \u001b[38;5;28;01mNone\u001b[39;00m] * embedding[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[32m     27\u001b[39m embedding = torch.cat((embedding.sin(), embedding.cos()), dim=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/diffusion-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/diffusion-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/diffusion-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/diffusion-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/diffusion-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/diffusion-examples/.venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (2x2048 and 4096x16384)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from typing import Tuple, Union\n",
    "\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_channels: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        self.embedding_mlp = nn.Sequential(\n",
    "            nn.Linear(n_channels // 4, n_channels),\n",
    "            Swish(),\n",
    "            nn.Linear(n_channels, n_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        \"\"\"\n",
    "        PE^{(1)}_{t, i} = sin(t/10000^(i/d-1))\n",
    "        PE^{(2)}_{t, i} = cos(t/10000^(i/d-1))\n",
    "        \"\"\"\n",
    "        \n",
    "        half_dim = self.n_channels // 8\n",
    "        embedding = math.log(10000) / (half_dim - 1)\n",
    "        embedding = torch.exp(torch.arange(half_dim, device=t.device) * -embedding)\n",
    "        embedding = t[:, None] * embedding[None, :]\n",
    "        embedding = torch.cat((embedding.sin(), embedding.cos()), dim=1)\n",
    "        \n",
    "        return self.embedding_mlp(embedding)\n",
    "\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "        in_channels: int, \n",
    "        out_channels: int, \n",
    "        time_channels: int, \n",
    "        n_groups: int=32, \n",
    "        dropout: float=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.GroupNorm(n_groups, in_channels),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.GroupNorm(n_groups, in_channels),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "        \n",
    "        self.time_embedding = nn.Sequential(\n",
    "            nn.Linear(time_channels, out_channels),\n",
    "            Swish(),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        h = self.conv1(x)\n",
    "        h += self.time_embedding(t)[:, :, None, None]\n",
    "        h = self.conv2(h)\n",
    "        return h + self.shortcut(x) # residual connection\n",
    "\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "        n_channels: int, \n",
    "        n_heads: int=4,\n",
    "        d_k: int=None,\n",
    "        n_groups: int=32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        if d_k is None:\n",
    "            d_k = n_channels\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        \n",
    "        self.norm = nn.GroupNorm(n_groups, n_channels)\n",
    "        \n",
    "        self.proj_k = nn.Linear(n_channels, n_heads * d_k)\n",
    "        self.proj_q = nn.Linear(n_channels, n_heads * d_k)\n",
    "        self.proj_v = nn.Linear(n_channels, n_heads * d_k)\n",
    "        \n",
    "        self.out = nn.Linear(n_heads * d_k, n_channels)\n",
    "        self.scale = d_k ** -0.5\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, t: Optional[torch.Tensor]=None) -> torch.Tensor:\n",
    "        \n",
    "        batch_size, n_channels, height, width = x.shape\n",
    "        x = x.view(batch_size, n_channels, -1).permute(0, 2, 1)  # reshape to (batch, seq, n_channels)\n",
    "        \n",
    "        k = self.proj_k(x).view(batch_size, -1, self.n_heads, self.d_k) # reshape to (batch, seq, n_heads, d_k)\n",
    "        q = self.proj_q(x).view(batch_size, -1, self.n_heads, self.d_k)\n",
    "        v = self.proj_v(x).view(batch_size, -1, self.n_heads, self.d_k)\n",
    "        \n",
    "        attention = torch.einsum('bihd,bjhd->bijh', q, k) # dot product attention Q@K^t\n",
    "        attention = attention * self.scale # scale by inverse of sqrt(d_k)\n",
    "        attention = attention.softmax(dim=2)\n",
    "        attention = torch.einsum('bijh,bjhd->bihd', attention, v)\n",
    "        \n",
    "        attention = attention.view(batch_size, -1, self.n_heads * self.d_k) # reshape (concat heads)\n",
    "        attention = self.output(attention) # project back down\n",
    "        attention += x\n",
    "        \n",
    "        return attention.perumte(0, 2, 1).view(batch_size, n_channels, height, width)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "        in_channels: int, \n",
    "        out_channels: int, \n",
    "        time_channels: int, \n",
    "        use_attention: bool=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.ResidualBlock(in_channels, out_channels, time_channels),\n",
    "            nn.AttentionBlock(out_channels) if use_attention else nn.Identity()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        return self.block(x, t)\n",
    "\n",
    "\n",
    "# class Bottleneck(nn.Module):\n",
    "    \n",
    "#     def __init__(self, n_channels: int, time_channels: int):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.block = nn.Sequential(\n",
    "#             ResidualBlock\n",
    "#         )\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "        image_channels: int=3,\n",
    "        n_channels: int=64,\n",
    "        channel_multipliers: Union[Tuple[int, ...], List[int]]=(1, 2, 2, 4),\n",
    "        uses_attention: Union[Tuple[bool, ...], List[bool]]=(False, False, True, True),\n",
    "        n_blocks: int=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.image_chennels = image_channels\n",
    "        self.n_channels = n_channels\n",
    "        self.channel_multipliers = channel_multipliers\n",
    "        self.uses_attention = uses_attention\n",
    "        self.n_blocks = n_blocks\n",
    "        \n",
    "        self.time_channels = n_channels * 4\n",
    "        self.time_embedding = TimeEmbedding(n_channels * self.time_channels)\n",
    "        \n",
    "        in_channels = out_channels = n_channels\n",
    "        \n",
    "        self.proj = nn.Conv2d(image_channels, n_channels, kernel_size=1)\n",
    "        self.encoder_modules = nn.ModuleList()\n",
    "        for i, channel_multiplier in enumerate(channel_multipliers):\n",
    "            \n",
    "            if i > 0:\n",
    "                out_channels = in_channels * channel_multiplier\n",
    "            else:\n",
    "                out_channels = n_channels\n",
    "            print(in_channels, out_channels)\n",
    "            \n",
    "            for _ in range(n_blocks):\n",
    "                self.encoder_modules.append(nn.Sequential(\n",
    "                    ResidualBlock(in_channels, out_channels, self.time_channels),\n",
    "                    AttentionBlock(out_channels) if uses_attention[i] else nn.Identity(),\n",
    "                ))\n",
    "                in_channels = out_channels\n",
    "            \n",
    "            if i < len(uses_attention) - 1: # if not at end of list\n",
    "                self.encoder_modules.append(nn.Upsample(scale_factor=0.5, mode='bilinear'))\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            ResidualBlock(in_channels, in_channels, self.time_channels),\n",
    "            AttentionBlock(in_channels),\n",
    "            ResidualBlock(in_channels, in_channels, self.time_channels)\n",
    "        )\n",
    "        \n",
    "        self.decoder_modules = nn.ModuleList()\n",
    "        for i, channel_multiplier in enumerate(reversed(channel_multipliers)):\n",
    "            \n",
    "            i = len(channel_multipliers) - (i + 1)\n",
    "            print(i)\n",
    "            \n",
    "            out_channels = in_channels // channel_multiplier\n",
    "            \n",
    "            for _ in range(n_blocks):\n",
    "                self.decoder_modules.append(nn.Sequential(\n",
    "                    ResidualBlock(in_channels, out_channels, self.time_channels),\n",
    "                    AttentionBlock(out_channels) if uses_attention[i] else nn.Identity(),\n",
    "                ))\n",
    "                in_channels = out_channels\n",
    "            \n",
    "            if i > 0:\n",
    "                self.encoder_modules.append(nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        \n",
    "        self.final = nn.Conv2d(in_channels, image_channels, 1),\n",
    "    \n",
    "    \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        t = self.time_embedding(t)\n",
    "        h_list = [x]\n",
    "        \n",
    "        x = self.proj(x)\n",
    "        for module in self.encoder_modules:\n",
    "            x = module(x, t)\n",
    "            h_list.append(x)\n",
    "        \n",
    "        x = self.bottleneck(x, t)\n",
    "        \n",
    "        for module in self.decoder_modules:\n",
    "            if isinstance(module, nn.Upsample):\n",
    "                x = module(x, t)\n",
    "            else:\n",
    "                s = h_list.pop()\n",
    "                x = torch.cat((x, s), dim=1)\n",
    "                x = module(x, t)\n",
    "        \n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "model = UNet()\n",
    "X = torch.rand((1, 3, 256, 256))\n",
    "t = torch.randint(1, 10, (1, 1))\n",
    "\n",
    "model(X, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25032c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8fe13b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Iterable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mIterable\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'Iterable' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "\n",
    "Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a31582c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
